{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3990c8-af13-4c09-b578-9dcd6c84d6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\HYAPP\\Anaconda3-2020.11\\envs\\birdnet\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\HYAPP\\Anaconda3-2020.11\\envs\\birdnet\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import pickle\n",
    "from DataGenerator_BN_emb_mem import DataGenerator\n",
    "from classification_head import create_model\n",
    "import augmentation as aug\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b453bd-57ba-4b0d-a780-9a72bc36e3a0",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with global data\n",
    "\n",
    "path_to_model = 'models/Argentina_Chaco'\n",
    "path_out = 'models/Argentina_Chaco/model_v1/'\n",
    "\n",
    "with_val = True # use validation set?\n",
    "tflite_threads = 5 # number of cpus\n",
    "epochs = 10\n",
    "round=1\n",
    "\n",
    "model_path_out = path_out + 'model_v1_' + str(round) + '.keras'\n",
    "model_path_in = path_out + 'model_v1_' + str(round-1) + '.keras'\n",
    "\n",
    "# Load data\n",
    "path_to_data = path_to_model + 'global_training_data/'\n",
    "\n",
    "with open(path_to_data + 'metadata/train_set.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/val_set.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/labels.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/weights.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "\n",
    "# Model hyperparameters\n",
    "dim = 3*48000 \n",
    "batch_size = 64\n",
    "n_classes = len(classes.keys())\n",
    "\n",
    "# Load impulse response matrix for distance effect augmentation\n",
    "ir_matrix = scipy.io.loadmat('irmatrix/irmatrix.mat')['irmatrix'] \n",
    "ir_dist = np.load(\"irmatrix/distances.npy\")\n",
    "\n",
    "# Set up augmentation strategy\n",
    "augmentation_params = {'ir_matrix':ir_matrix, 'ir_distances':ir_dist, \n",
    "                       'p_pitch_shift':0.3, 'pitch_shift_steps':1, \n",
    "                       'p_time_stretch':0.3, 'time_stretch_rate':0.08, \n",
    "                       'p_noise_red':0.3, 'noise_beta_params':[5,2], \n",
    "                       'mixup_norm_std':15,\n",
    "                       'mask_lambda':0.5, 'mask_max_length':0.25,\n",
    "                       'noise_gen_beta_params':[1,1], \n",
    "                       'p_resample':0.6, 'resample_target_srs':[16000, 22050, 24000], \n",
    "                       'target_len':dim, 'orig_sr':48000}\n",
    "p_mixup = 0.3\n",
    "\n",
    "# Generators \n",
    "training_generator = DataGenerator(path_to_data=path_to_data, data_paths=train_data, \n",
    "                                   labels=labels, weights=weights, batch_size=batch_size, dim=dim, \n",
    "                                   n_classes=n_classes, shuffle=True, augment=True, augm_params=augmentation_params, \n",
    "                                   p_mixup=p_mixup, p_dist_effect=1, TFLITE_THREADS=tflite_threads)\n",
    "\n",
    "if round==1:\n",
    "    model = create_model(n_classes)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=1e-3), \n",
    "                  metrics=['binary_accuracy'])\n",
    "else: \n",
    "    model = tf.keras.models.load_model(model_path_in)\n",
    "\n",
    "if with_val:\n",
    "    validation_generator = DataGenerator(path_to_data=path_to_data, data_paths=val_data,  \n",
    "                                         labels=labels, weights=weights, batch_size=batch_size, dim=dim, \n",
    "                                         n_classes=n_classes, shuffle=True, augment=False, TFLITE_THREADS=tflite_threads)\n",
    "    history = model.fit(x = training_generator, validation_data = validation_generator, epochs = epochs)  \n",
    "else:\n",
    "    history = model.fit(x = training_generator, epochs = epochs) \n",
    "    \n",
    "if(os.path.isdir(path_out)):\n",
    "    model.save(model_path_out)\n",
    "else:\n",
    "    os.mkdir(path_out)\n",
    "    model.save(model_path_out)\n",
    "\n",
    "print(\"Model trained and saved\")\n",
    "\n",
    "np.save(path_out + 'training_history_' + str(round) + '.npy', history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1da474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue with local data\n",
    "\n",
    "with_val = True # use validation set?\n",
    "tflite_threads = 5 # number of cpus\n",
    "epochs = 15\n",
    "round=2\n",
    "\n",
    "model_path_out = path_out + 'model_v1_' + str(round) + '.keras'\n",
    "model_path_in = path_out + 'model_v1_' + str(round-1) + '.keras'\n",
    "\n",
    "# Load data\n",
    "path_to_data = path_to_model + 'local_training_data/'\n",
    "\n",
    "with open(path_to_data + 'metadata/train_set.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/val_set.pkl', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/labels.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/weights.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "with open(path_to_data + 'metadata/classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "\n",
    "# Model hyperparameters\n",
    "dim = 3*48000 \n",
    "batch_size = 64\n",
    "n_classes = len(classes.keys())\n",
    "\n",
    "# Load impulse response matrix for distance effect augmentation\n",
    "ir_matrix = scipy.io.loadmat('irmatrix/irmatrix.mat')['irmatrix'] \n",
    "ir_dist = np.load(\"irmatrix/distances.npy\")\n",
    "\n",
    "# Set up augmentation strategy\n",
    "augmentation_params = {'ir_matrix':ir_matrix, 'ir_distances':ir_dist, \n",
    "                       'p_pitch_shift':0.3, 'pitch_shift_steps':1, \n",
    "                       'p_time_stretch':0.3, 'time_stretch_rate':0.08, \n",
    "                       'p_noise_red':0.3, 'noise_beta_params':[5,2], \n",
    "                       'mixup_norm_std':15,\n",
    "                       'mask_lambda':0.5, 'mask_max_length':0.25,\n",
    "                       'noise_gen_beta_params':[1,1], \n",
    "                       'p_resample':0.6, 'resample_target_srs':[16000, 22050, 24000], \n",
    "                       'target_len':dim, 'orig_sr':48000}\n",
    "p_mixup = 0.3\n",
    "\n",
    "# Generators \n",
    "training_generator = DataGenerator(path_to_data=path_to_data, data_paths=train_data, \n",
    "                                   labels=labels, weights=weights, batch_size=batch_size, dim=dim, \n",
    "                                   n_classes=n_classes, shuffle=True, augment=True, augm_params=augmentation_params, \n",
    "                                   p_mixup=p_mixup, p_dist_effect=1, TFLITE_THREADS=tflite_threads)\n",
    "\n",
    "if round==1:\n",
    "    model = create_model(n_classes)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=RMSprop(learning_rate=1e-3), \n",
    "                  metrics=['binary_accuracy'])\n",
    "else: \n",
    "    model = tf.keras.models.load_model(model_path_in)\n",
    "\n",
    "if with_val:\n",
    "    validation_generator = DataGenerator(path_to_data=path_to_data, data_paths=val_data,  \n",
    "                                         labels=labels, weights=weights, batch_size=batch_size, dim=dim, \n",
    "                                         n_classes=n_classes, shuffle=True, augment=False, TFLITE_THREADS=tflite_threads)\n",
    "    history = model.fit(x = training_generator, validation_data = validation_generator, epochs = epochs)  \n",
    "else:\n",
    "    history = model.fit(x = training_generator, epochs = epochs) \n",
    "    \n",
    "if(os.path.isdir(path_out)):\n",
    "    model.save(model_path_out)\n",
    "else:\n",
    "    os.mkdir(path_out)\n",
    "    model.save(model_path_out)\n",
    "\n",
    "print(\"Model trained and saved\")\n",
    "\n",
    "np.save(path_out + 'training_history_' + str(round) + '.npy', history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed6da4",
   "metadata": {},
   "source": [
    "# Observe training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Argentina_Chaco/'\n",
    "rounds = 2 # in how many runs was the model trained\n",
    "\n",
    "# visualize results of network training\n",
    "def plot_results(history, val = True):\n",
    "    acc = history['binary_accuracy']\n",
    "    loss = history['loss']\n",
    "    if val:\n",
    "        val_acc = history['val_binary_accuracy']\n",
    "        val_loss = history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    if val:\n",
    "        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training (and validation) accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    if val:\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training (and validation) loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "joint_history = {'loss':[], 'binary_accuracy':[], 'val_loss':[], 'val_binary_accuracy':[]}\n",
    "\n",
    "for i in range(rounds):\n",
    "    with open(model_name + 'training_history_' + str(i+1) + '.pkl', 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        for stat in ['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy']:\n",
    "            joint_history[stat] = joint_history[stat] + history[stat]\n",
    "\n",
    "plot_results(joint_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
